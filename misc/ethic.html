<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>ETHICAL REFLECTIONS</title>
  	<link rel="stylesheet" href="../styles/style.css">
      <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      <link href="https://fonts.googleapis.com/css2?family=Libre+Franklin:ital,wght@1,300&family=Oswald&family=Titillium+Web&display=swap" rel="stylesheet">
      <link href="https://fonts.googleapis.com/css2?family=Kdam+Thmor+Pro&display=swap" rel="stylesheet">

</head>

<body background="C:\Users\chldp\OneDrive\바탕 화면\Website\images\background.jpg">
<header class="header">

    <div class = "header__logo">
        <a href="#">
            <h1>AI SENSOR TECHNOLOGY &
            AUTONOMOUS VEHICLES</h1>
        </a>
    </div>

    <div class="header__gnb">
        <ul>
            <li><a href="../index.html">HOME</a></li>
            <li><a href="topic.html">TOPIC</a></li>
            <li><a href="opportunity.html">OPPORTUNITY</a></li>
            <li><a href="choice.html">CHOICE</a></li>
            <li><a href="risk.html">RISK</a></li>
            <li><a href="ethic.html">ETHICAL REFLECTIONS</a></li>
            <li><a href="references.html">REFERENCE</a></li>
        </ul>
    </div>
</header>


<Ethic class="Ethic">

    <div class="Ethic" style='text-indent:15px'>
        <h6>What are the moral issues that autonomous vehicles using this sensor can face? 
        </br>Sensors replace human eyes and algorithms in the system determine drivers and road conditions. When sensors complement their role in price or in many respects are fully capable of performing their role, responsibility is borne by a system of judgement and decision-making. At present, many companies are making efforts to make it practical because sensors are not as advanced as human eyes. There are several reasons why it is difficult for self-driving cars to be put into practical use immediately.
        </h6>
    </div>
</Ethic>

<Response class="Response">

    <div class="Response" style='text-indent:15px'>
        <h1>Response to unexpected situations
        </h1>
        <p> First, self-driving cars do not respond effectively and stably to unexpected situations. A city centre is a place where there are many unexpected accidents, such as vehicles interrupting or people entering the roadway. He said that based on traffic data in the western United States, hundreds of unexpected situations on the road were applied to computers, with a human accident rate of almost 0 percent, while the algorithm's accident rate is still over 20 percent. The ability to recognize pedestrians while driving at high speed does not yet exceed human agility. In fact, humans recognized human figures hundreds of metres ago, but cameras are not yet capable of that resolution. This means that even if only 5-10% of these situations are encountered on the road, they still lack the ability to cope with uncertainties. The simulations I did on Google Collaboration last time also showed that I had more difficulty recognizing people than cars and that I had difficulty recognizing people who were far away or not standing properly. The resolution of the photo file was 500 kb and low-resolution images. High-resolution images take a long time to process and are expensive. Recently, Korean researchers have developed artificial intelligence technology that can increase the resolution of self-driving cars ' eyes and lower production costs. The research team developed a high-resolution image generation method for neuromorphic cameras. A neuromorphic camera is a device that recognizes images by detecting changes in brightness per pixel and can recognize dynamic images well as if the surrounding environment changes every moment. As it can be made and utilised relatively inexpensively, it is currently attracting attention as a technology that replaces expensive rider sensors that self-driving cars mount to recognize surrounding environment images. However, instead of processing dynamic images at high speed, the resolution is low. Therefore, research is underway around the world to increase the resolution of neuromorphic cameras. Companies that actively participate in the development of unmanned vehicles also believe that it is more efficient to focus on the development of neuromorphic cameras than to invest in riders. The research team developed A deep learning technology that converts low-resolution images of neuromorphic cameras to high-resolution by utilising neural networks that mimic human brain functions. Through this, it is expected that it will contribute to solving resolution problems that have been an obstacle to the commercialization of neuromorphic cameras. 
</p>

    </div>
</Response>

<Communication class="Communication">

    <div class="Communication" style='text-indent:15px'>
<h1>Communication with pedestrians
</h1>
<p>Another problem with autonomous driving is cooperative driving. Where there is no signal, people find out the intention of the other person by making eye contact with each other and intervening or yielding. Such collaboration is a field that is difficult to overcome as an autonomous vehicle due to human characteristics. Of course, the cost of installing analysis and first aid equipment, including precise cameras necessary for self-driving cars, is not easy. In particular, it is pointed out that it is still too early to combine with the Internet of Things in order for autonomous cars to succeed, but all transportation infrastructure is not enabled for things. 
</p>
<p> Currently, the practical use of self-driving cars is being delayed due to various obstacles, and some argue that the strategy should be changed. It is not to allow all autonomous cars in the city to drive at once, but to change the range of alternative traffic from "all cars" to "some cars." This means that there is no need to tie them to the range of self-driving cars at once, as long-distance transportation such as short-distance and highways as well as small towns and cities have their own characteristics. The interesting suggestion here is that long-distance traffic such as highways should be replaced by self-driving cars, but in small communities such as towns and campuses, such as small communities with a radius of one kilometre, should be replaced by electric bicycles rather than cars. These electric bicycles are halfway between conventional cars and bicycles, with a maximum speed of about 30 km, faster than walking speed, but much slower than cars. It weighs less than 50 kilograms, which is a little heavier than a bicycle and uses electricity, reducing pollutant emissions by more than 60%. This idea sounded pretty convincing to me. It is important to reduce the total number of vehicles with regular autonomous cars, but it also means that there is a need to replace cars in small communities. In this way, the total number of cars can be greatly reduced and the part that effectively reduces the time and resources wasted to travel close distances can be expected. 
</p>
    </div>
</Communication>



<Morality class="Morality">

    <div class="Morality" style='text-indent:15px'>
<h1>Self-driving cars, trust and morality are key 
</h1>

<p>The reason why many people are interested in self-driving cars is not only because this function is not limited to personal luxury vehicles, but also because ordinary people can purchase self-driving cars, so they can become universal cars. The sensors introduced on the website correspond to the performance part of the car because they are used to collect data inputs. However, the Achilles heel of an autonomous car is far from the performance of the car and is closer to artificial intelligence that makes judgments in this system. When you think of the GPS that you are currently using, you can't precisely judge the direction or location you're looking at when the car is stopped or just left, and the driver immediately guides you in the wrong direction, and the driver follows the navigation. Then, when the system completes a proper calculation again, providing more accurate results, the driver will then find a place to make a U-turn. This means that human judgement is still better in the current situation than relying on navigation alone. If the one-way load is not entered into the system, the car faces a situation where it can reverse. In addition, unlike human drivers, self-driving cars always objectively grasp the current situation because artificial intelligence processes information obtained from various sensors in an instant. Nevertheless, it is a physical phenomenon that the car moves, so it cannot prevent all unexpected accidents. In other words, it seems that a car suddenly crosses the centre line in the opposite lane or a child suddenly jumps into the road. To make a more complicated situation, an accident occurred while an autonomous car was driving, putting the life of one passenger in danger, and it is assumed that several pedestrians could be hit and killed by a car if they turn the steering wheel to avoid it. In such an extreme situation, it is questionable whether artificial intelligence, which moves autonomous vehicles, should protect one passenger who is the owner or save a number of passers-by. In this case, human drivers respond close to reflective behaviour without fully grasping the situation, but self-driving cars choose the next best way to do it. In other words, if the damage is inevitable, it is decided in the direction of minimising damage. In terms of people, the situation just before the accident will return to slow motion, giving them time to decide "how to finish the accident." Of course, artificial intelligence follows the program's behavioural guidelines for each situation, but it means that the person who created artificial intelligence decides how to act in this situation. An interesting self-driving car had a questionnaire about its behaviour guidelines, for example, when ten people suddenly appeared in front of it and all ten people died if they did, but when they turned the steering wheel, they hit the wall and the passengers died. Most people judged it more moral to sacrifice one passenger instead of ten pedestrians. However, when the passenger assumed that it was him, he chose to save one of his passengers. Making AI that values multiple lives can avoid pointing fingers, but consumers who buy cars think they should save themselves first.
</p>

<img src="/Website/images/irobot.JPG">
<img src="/Website/images/irobot2.JPG">
<img src="/Website/images/irobotgif.gif">
<p>Humans are far superior to artificial intelligence to cope with unexpected situations while driving. In the event of an accident, humans momentarily make the best decision for them. When boarding with your child, you take the most human measure of sacrificing yourself, thinking about the safety of the child before yourself. In the movie I-Robot, a detective falls into the water with his young daughter. When they almost die,  the robot comes and breaks the window. The detective instructs the robot his daughter to be rescued first, but the robot rescues him first. This is because the survival rate of the detective was 45%, but the survival rate of the daughter was only 11%. The robot that saved him was faithful to the robot's principle of saving people with high survival rates first, but eventually violated Del Spunner's orders. This contradiction can happen because humans, unlike computers, do not move only with common sense. It is impossible for a programmer to input all the variables of many car accidents. Nevertheless, experts disagree that autonomous vehicles using artificial intelligence programs will reduce the accident rate rather than driving by humans because most car accidents currently occur due to driver negligence. 
</p>
<p>And in this situation, who will be the subject of setting artificial intelligence for autonomous vehicles. Whether it is left to the autonomy of the automobile industry or the government should issue guidelines or allow drivers to press buttons to choose. If the government gives authority, export vehicles must adjust their settings to suit the situation in each country. This field deals with human life and argues that problem-solving should precede in various areas, including responsibility for accident risks. The first point to be pointed out is to determine the timing of the change of control between autonomous vehicles and drivers or the scope of technical connection in terms of road traffic. This raises the question of whether privacy comes first or public information comes first. In order to drive, various signals and data must be exchanged, which can lead to privacy infringement problems. Since self-driving cars themselves are operated as artificial intelligence programs, security problems against hacking or terrorist organizations may arise, so they should be prepared for attacks by terrorists or hackers. 
</p>
<p>Experts cite 'legal and ethical problems' as a task to be solved first before developing self-driving cars. This is because if artificial intelligence, not humans, is left to judge how to respond to accidents, various social conflicts can arise, ranging from whether artificial intelligence can trust autonomous judgments and where it is responsible for accidents. In particular, in the event of an accident, the resolution of legal ethical issues such as legal responsibility, self-driving insurance, and where to prioritise drivers and pedestrians should be preceded. Considering that operating programming is organised by humans, it has also been raised as a problem that human prejudice can be involved. The time has come for a debate on whether it is utilitarianism or moral principles, in other words, whether cars should act like humans or follow moral laws as reported by the Ethics Committee. After creating a minimum ethical code for developing software related to self-driving cars, we should continue to develop better-unmanned vehicles by combining advanced software and hardware technologies.
</p>
    </div>
</Morality>

</body>



</html>